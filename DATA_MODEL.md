# ğŸ’¾ Data Model

> Database schema, Redis keys, and Kafka message formats

---

## Overview

Flux-Gate uses three data stores with distinct purposes:

| Store | Purpose | Data Type |
|-------|---------|-----------|
| **PostgreSQL** | Permanent record (System of Record) | Orders, Products |
| **Redis** | Transient state (Real-time) | Inventory, Rate limits, Idempotency |
| **Kafka** | Message queue (Durable) | Order events |

---

## PostgreSQL Schema

### Products Table

```sql
CREATE TABLE IF NOT EXISTS products (
    id TEXT PRIMARY KEY,
    stock INTEGER NOT NULL
);

-- Example data
INSERT INTO products (id, stock) VALUES ('iphone-15', 100);
```

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | TEXT | PRIMARY KEY | Product identifier (e.g., "iphone-15") |
| `stock` | INTEGER | NOT NULL | Current inventory count |

**Notes**:
- Stock is decremented with optimistic locking: `WHERE stock > 0`
- This is the **safety net**; Redis is the primary inventory control
- No foreign key to orders (intentional decoupling)

### Orders Table

```sql
CREATE TABLE IF NOT EXISTS orders (
    id TEXT PRIMARY KEY,
    product_id TEXT NOT NULL,
    user_id TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Example data
INSERT INTO orders (id, product_id, user_id) 
VALUES ('550e8400-e29b-41d4-a716-446655440000', 'iphone-15', 'user-12345');
```

| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| `id` | TEXT | PRIMARY KEY | UUID generated by ingestion API |
| `product_id` | TEXT | NOT NULL | Reference to products.id |
| `user_id` | TEXT | NOT NULL | Identifier of purchasing user |
| `created_at` | TIMESTAMP | DEFAULT NOW | Order creation timestamp |

**Notes**:
- `id` is generated at API layer (before Kafka), ensuring idempotency
- No foreign key constraint on `product_id` for performance
- Worker inserts only after successful stock decrement

---

## Redis Key Design

### Inventory Keys

```
product:{productId}:stock = {integer}
```

| Key Pattern | Example | Value | TTL |
|-------------|---------|-------|-----|
| `product:{id}:stock` | `product:iphone-15:stock` | `100`, `99`, `0` | None (persistent) |

**Operations**:
```lua
-- Initialize
SET product:iphone-15:stock 100

-- Atomic decrement (via Lua script)
local current = redis.call('GET', 'product:iphone-15:stock')
if tonumber(current) >= 1 then
    redis.call('DECRBY', 'product:iphone-15:stock', 1)
    return 1
end
return 0
```

### Rate Limiting Keys

```
rate:{unix_timestamp} = {integer}
```

| Key Pattern | Example | Value | TTL |
|-------------|---------|-------|-----|
| `rate:{ts}` | `rate:1705234800` | `42` (request count) | 2 seconds |

**Operations**:
```typescript
const timestamp = Math.floor(Date.now() / 1000);
const key = `rate:${timestamp}`;
const count = await redis.incr(key);
if (count === 1) {
    await redis.expire(key, 2);  // Cleanup after 2s
}
```

**Why 2 second TTL?**  
Keys from previous second should be cleaned up, but we allow 1 second buffer for clock skew.

### Idempotency Keys

```
idempotency:{uuid} = "1"
```

| Key Pattern | Example | Value | TTL |
|-------------|---------|-------|-----|
| `idempotency:{key}` | `idempotency:550e8400-e29b-41d4-a716-446655440000` | `"1"` | 60 seconds |

**Operations**:
```typescript
// Check
const exists = await redis.get(`idempotency:${key}`);
if (exists) return "duplicate";

// ... process order ...

// Mark as processed
await redis.set(`idempotency:${key}`, '1', 'EX', 60);
```

**Why 60 second TTL?**  
- Long enough to handle network retries and double-clicks
- Short enough to avoid memory bloat
- After expiry, same key could theoretically be reused (acceptable)

---

## Redis Key Summary

| Key Pattern | Purpose | TTL | Cardinality |
|-------------|---------|-----|-------------|
| `product:{id}:stock` | Inventory count | None | O(products) |
| `rate:{timestamp}` | Request count per second | 2s | O(1) at any time |
| `idempotency:{uuid}` | Duplicate detection | 60s | O(requests in last 60s) |

### Memory Estimation

```
Inventory:     ~100 bytes Ã— num_products
Rate limit:    ~50 bytes Ã— 2 (current + previous second)
Idempotency:   ~100 bytes Ã— requests_per_minute

Example at 10k RPS:
- Inventory: 100 products Ã— 100 bytes = 10 KB
- Rate limit: 2 Ã— 50 bytes = 100 bytes
- Idempotency: 600k requests Ã— 100 bytes = 60 MB

Total: ~60 MB (well within Redis capacity)
```

---

## Kafka Message Schema

### Topic: `orders`

**Configuration**:
| Setting | Value | Reason |
|---------|-------|--------|
| Partitions | 1 | Strict ordering (demo) |
| Replication | 1 | Local development |
| Retention | 7 days | Replay capability |

**Message Format**:
```json
{
  "orderId": "550e8400-e29b-41d4-a716-446655440000",
  "productId": "iphone-15",
  "userId": "user-12345",
  "timestamp": 1705234800123
}
```

| Field | Type | Description |
|-------|------|-------------|
| `orderId` | string (UUID) | Unique order identifier |
| `productId` | string | Product being purchased |
| `userId` | string | Purchasing user identifier |
| `timestamp` | number | Unix timestamp in milliseconds |

**Producer Code**:
```typescript
await producer.send({
    topic: 'orders',
    messages: [{
        value: JSON.stringify({
            orderId: uuidv4(),
            productId,
            userId,
            timestamp: Date.now()
        })
    }]
});
```

**Consumer Code**:
```typescript
await consumer.run({
    eachMessage: async ({ message }) => {
        const { orderId, productId, userId } = JSON.parse(message.value);
        // Process order...
    }
});
```

---

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DATA FLOW                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  1. API receives POST /order                                        â”‚
â”‚     â””â”€â–¶ Check: rate:{timestamp} < 50? â†’ Else 302 redirect           â”‚
â”‚                                                                     â”‚
â”‚  2. Check idempotency                                               â”‚
â”‚     â””â”€â–¶ GET idempotency:{key} â†’ If exists, return cached            â”‚
â”‚                                                                     â”‚
â”‚  3. Decrement inventory (Lua script)                                â”‚
â”‚     â””â”€â–¶ product:{id}:stock -= 1 â†’ If fail, return 409               â”‚
â”‚                                                                     â”‚
â”‚  4. Produce to Kafka                                                â”‚
â”‚     â””â”€â–¶ Topic: orders                                               â”‚
â”‚         Message: { orderId, productId, userId, timestamp }          â”‚
â”‚                                                                     â”‚
â”‚  5. Mark idempotency                                                â”‚
â”‚     â””â”€â–¶ SET idempotency:{key} '1' EX 60                             â”‚
â”‚                                                                     â”‚
â”‚  6. Return 200 "Order accepted"                                     â”‚
â”‚                                                                     â”‚
â”‚  â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ ASYNC BOUNDARY â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€                â”‚
â”‚                                                                     â”‚
â”‚  7. Worker consumes from Kafka                                      â”‚
â”‚     â””â”€â–¶ BEGIN TRANSACTION                                           â”‚
â”‚         UPDATE products SET stock = stock - 1                       â”‚
â”‚                WHERE id = $1 AND stock > 0                          â”‚
â”‚         INSERT INTO orders (id, product_id, user_id)                â”‚
â”‚                VALUES ($orderId, $productId, $userId)               â”‚
â”‚         COMMIT                                                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Versioning Strategy

### Current Approach (v1)
- No explicit versioning in schemas
- Message format is simple JSON
- Schema changes require coordinated deploys

### Future Enhancements

| Approach | Use Case |
|----------|----------|
| **Avro + Schema Registry** | Type-safe schema evolution |
| **Message Versioning** | `{ "version": 2, "data": {...} }` |
| **Database Migrations** | Flyway/Liquibase for PostgreSQL |

---

## Consistency Considerations

### Redis â†” PostgreSQL Sync

| Scenario | Redis State | PostgreSQL State | Resolution |
|----------|-------------|------------------|------------|
| Normal | stock = 50 | stock = 50 | In sync |
| Order in flight | stock = 49 | stock = 50 | Will sync after worker processes |
| Worker crashed | stock = 49 | stock = 50 | Worker resumes, DB catches up |
| Redis failure | N/A | stock = 50 | Re-initialize Redis from DB |

### Reconciliation

If Redis and PostgreSQL diverge:
```sql
-- Trust PostgreSQL as source of truth
SELECT stock FROM products WHERE id = 'iphone-15';
-- Update Redis
SET product:iphone-15:stock {db_value}
```
